# Dockerfile для создания образа Jupyter Notebook с поддержкой Spark и ClickHouse.
# Этот Dockerfile:
#    - Устанавливает необходимые системные утилиты (wget).
#    - Загружает и устанавливает JDBC драйвер ClickHouse для работы со Spark.
#    - Устанавливает Python библиотеки для анализа данных.
#    - Настраивает рабочую директорию и пользователя.

FROM jupyter/pyspark-notebook:latest

USER root

# Убедимся, что wget есть
RUN apt-get update && apt-get install -y --no-install-recommends wget && \
    apt-get clean && rm -rf /var/lib/apt/lists/*

# Загрузка JDBC драйвера ClickHouse и определение пути к Spark
ARG CLICKHOUSE_JDBC_VERSION="0.4.6"
RUN mkdir -p /tmp/clickhouse && \
    wget https://repo1.maven.org/maven2/com/clickhouse/clickhouse-jdbc/${CLICKHOUSE_JDBC_VERSION}/clickhouse-jdbc-${CLICKHOUSE_JDBC_VERSION}-shaded.jar -P /tmp/clickhouse && \
    SPARK_JARS_DIR=$(find /usr/local -name "jars" -type d | grep -i spark | head -1) && \
    if [ -z "$SPARK_JARS_DIR" ]; then \
        echo "Spark jars directory not found, trying alternative paths" && \
        SPARK_JARS_DIR=$(find /opt -name "jars" -type d | grep -i spark | head -1); \
    fi && \
    if [ -z "$SPARK_JARS_DIR" ]; then \
        echo "ERROR: Could not find Spark jars directory" && exit 1; \
    else \
        echo "Found Spark jars directory: $SPARK_JARS_DIR" && \
        cp /tmp/clickhouse/clickhouse-jdbc-${CLICKHOUSE_JDBC_VERSION}-shaded.jar $SPARK_JARS_DIR/ && \
        echo "ClickHouse JDBC driver copied to Spark jars directory" && \
        rm -rf /tmp/clickhouse; \
    fi

# Установка дополнительных библиотек Python
RUN pip install --no-cache-dir pandas scikit-learn matplotlib seaborn requests beautifulsoup4 clickhouse-driver

# Вернуться к пользователю jovyan
USER $NB_UID

# Рабочая директория
WORKDIR /home/jovyan/work
